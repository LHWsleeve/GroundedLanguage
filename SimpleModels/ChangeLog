2016-03-13  Deniz Yuret  <dyuret@ku.edu.tr>

	* notation:
	B = before
	A = after
	T = targetpos
	M = moving (source) block id
	N = neighbor (reference) block id
	R = relpos (direction) id

	model13: A+T => N works in ~64K iters
	model14: A+T => N+R works
	model15: A+B => M works in ~8K iters
	model16: A+B => N does not work
	model17: A+B => T works in ~1M iters

2016-03-10  Deniz Yuret  <dyuret@ku.edu.tr>

	* model15.jl: Finding the block (id) moved given before and after
	worlds (coor).

2016-03-09  Deniz Yuret  <dyuret@ku.edu.tr>

	* model14.jl: Find a nearby block (id) and relative direction (id)
	given a world (coor) and a target position (coor).  Can be done
	using single hidden layer MLP.

	* model13.jl: Find a nearby block (id) given a position (coor) in
	a world (coor).  A regular single hidden layer network able to
	learn this.

2016-03-02  Deniz Yuret  <dyuret@ku.edu.tr>

	* models:
	01 y=WPx coor W on grid, P is identity matrix
	02 01 + coor on unit circle
	03 01 + coor has n+1 dims
	04 01 + P is permutation matrix
	05 01 + synonyms, many-to-one mapping from words to objects
	06 y=f(Aw+Bx) additive model
	07 y=x1*x2 learning to multiply
	08 y=WPx+Vr learning relative positions
	09 y=W(Ax+Br)+(Cx+Dr) don't know which is noun and which is prep
	10 y=W(Ax+Br) it turns out the extra terms ARE necessary
	11 starting with 09, minibatching with world fixed in minibatch
	12 starting with 09, trying to minibatch with changing world, does not seem possible.

	TODO:
	- think about convolution for 12
	- write summary
	- replicate with grid
	- absolute position words
	- hook up with RNN

2016-02-24  Deniz Yuret  <dyuret@ku.edu.tr>

	* TODO:
	+ does shuffling vocab slow training down, it shouldn't.
	+ synonyms (more than one word referring to the same object)
	+ additive model: a*world+b*word? show it doesn't work: probably does but more examples, more layers etc. (model06) first solve multiplication as an example (model07).
	x do we need extra layers for coor transformation?
	+ can we add a relative position?
	? convolution in coor: can we have minibatches and do matmul with convolution?
	= grid model: how does grid help/hurt?

2016-02-17  Deniz Yuret  <dyuret@ku.edu.tr>

	* SimpleModels: The plan is to experiment with a bunch of simple
	models to see how representation effects learning.  We will ignore
	language for now and focus on two simple problems:

	1. before, after -> diff
	2. before, diff -> after

	Here before and after are world states, represented as grid or
	coor.  Diff is a description of what changed.  We assume only a
	single block moved.  We could talk about the id/grid/coor of the
	moving block (source).

	1.1 before(coor,grid), after(coor,grid) -> source(id,coor,grid) (12 combinations)

	We could talk about the grid/coor of the target location.

	1.2 before(coor,grid), after(coor,grid) -> target(coor,grid) (8 combinations)

	For task 2 we need to specify both the source and the target.

	2 before(coor,grid), source(id,coor,grid), target(coor,grid) -> after(coor,grid) (24 combinations)

	The meaningful problem here is #2, as it corresponds most closely
	with language interpretation.  During training, we observe a
	world, hear an utterance, see the world change.  After we learn,
	we observe a world, hear an utterance, figure out what should
	change (understanding), or we observe a change and describe it
	with an utterance (generation).  In #2 we assume the utterance
	comes to us already parsed an our job is to map the parsed symbols
	to the world.  Let's say this interpretation includes discrete
	id's for source and reference objects and relative position.  We
	need to learn how to map these to world coordinates.  The simpler
	problem is source interpretation:

	2.1 before(coor,grid), source(id) -> source(coor,grid)

	i.e. can we point to the object whose name is given to us.

	Next we have prediction of target position from the reference
	object and relative position:

	2.2 before(coor,grid), robj(id), rpos(id) -> target(coor,grid)

	This predicts empty locations, but we could also describe an
	object (instead of a location) by giving its relative position to
	another object.

	2.3 before(coor,grid), robj(id), rpos(id) -> tobj(id,coor,grid)

	* 2.1-coor: First let's design models for these problems by hand.
	To solve 2.1 in coor representation first we need to figure out a
	permutation matrix from the source id to our internal index.  Let
	s(n,1) be a one-hot vector for source id, P(n,n) a permutation
	matrix, W(3,n) world state, and x(n,1) a one-hot vector indicating
	the column for the location of s in W, and y(3,1) the location of
	the source.  The simplest model is: y=WPs, and all we need to
	figure out is P.

	* 2.1-grid: The simplest way to solve 2.1 in grid representation
	is to have n filters tuned to n objects.  Each filter is of size
	(1,1,n+2,1) and each will reveal the location of one object.  So
	this is a (1,1,n+2,n) filter bank, applied to (w+2,h+2,n+2,1)
	input grid.  The convolution will output y=(w+2,h+2,n,1), the n
	output channels representing n objects.  We need to pick one
	channel out of this as our final output.  Is there a neural net
	version of the indexing operation y[:,:,i,1]?  If we minibatch i
	will be an array of indices.  Or maybe instead of applying all the
	filters, we filter them based on s and just apply the one.  That
	looks like an indexing operation as well:
	(1,1,n+2,n)->(1,1,n+2,1).  With coor we had matrix multiply.  Is
	there a generalized version?

	If we can pull this off, it looks like a nice architecture: words
	pick filters, filters act on topographic maps and give other
	topographic maps, the resultant topographic maps guide behavior.
	Words can act either before or after the filter application.
